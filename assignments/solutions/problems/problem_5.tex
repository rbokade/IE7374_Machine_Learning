\section{Problem 5}

	\begin{align*}
		\mu_{\text{MLE}} & = \frac{1}{n} \sum_{i=1}^{n} x_{i} \\
		\sigma_{\text{MLE}}^{2} & = \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \mu_{\text{MLE}})^{2}
	\end{align*}
	
	\begin{itemize}
		\item 
			\begin{align*}
				\mathbb{E}[\sigma_{\text{MLE}}^{2}] & = \mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \mu_{\text{MLE}})^{2}	\right] \\
				& = \mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \bar{x})^{2}	\right] 
				= \mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (x_{i}^{2} - 2x_{i}\bar{x} + \bar{x}^{2}) \right] 
				= \frac{1}{n} \mathbb{E} \left[ \sum_{i=1}^{n} (x_{i}^{2}) - 2n\bar{x}^{2} +  n \bar{x}^{2} \right] \\
				& = \frac{1}{n} \mathbb{E} \left[ \sum_{i=1}^{n} (x_{i}^{2}) - n\bar{x}^{2} \right]
				= \frac{1}{n} \mathbb{E} \left[ \sum_{i=1}^{n} x_{i}^{2} \right] - \mathbb{E} \left[ \bar{x}^{2} \right]
				= \mathbb{E} \left[ x_{i}^{2} \right] - \mathbb{E} \left[ \bar{x}^{2} \right]
			\end{align*}
			We know that $Var[X] = \mathbb{E}[x^{2}] - \mathbb{E}[x]^{2}$ from the definition of variance.
			\begin{align*}
				\mathbb{E} \left[ x_{i}^{2} \right] - \mathbb{E} \left[ \bar{x}^{2} \right] & = \sigma_{x}^{2} + \mathbb{E}[x_{i}]^{2} - \sigma_{x}^{2} - \mathbb{E}[x_{i}]^{2} = \sigma_{x}^{2} - \sigma_{\bar{x}}^{2} \\
				& = \sigma_{x}^{2} - Var[\bar{x}] = \sigma_{x}^{2} - Var \left[ \frac{1}{n} \sum_{i=1}^{n} x_{i} \right] \\
				& = \sigma_{x}^{2} - \left( \frac{1}{n} \right)^{2} Var\left[ \sum_{i=1}^{n} x_{i} \right]
			\end{align*}
			Now, 
			\begin{align*}
				\sigma_{x}^{2} - \left( \frac{1}{n} \right)^{2} Var\left[ \sum_{i=1}^{n} x_{i} \right] 
				= \sigma_{x}^{2} - \left( \frac{1}{n} \right)^{2} n \sigma_{x}^{2} - \frac{1}{n} \sigma_{x}^{2}	
				= \boxed{ \frac{n - 1}{n} \sigma_{x}^{2} < \sigma_{x}^{2} }
			\end{align*}
			Thus, $\sigma_{\text{MLE}}^{2}$ is an unbiased estimator of $\sigma^{2}$.
		\item
			\begin{align*}
				\mathbb{E}[\hat{\sigma}^{2}] & = \mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \mu)^{2}	\right]
				= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E} \left[ (x_{i} - \mu)^{2}	\right]
				= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E} \left[ x_{i}^{2} - 2x_{i}\mu + \mu^{2} \right] \\
				& = \frac{1}{n} \left[ \sum_{i=1}^{n} \mathbb{E}[x_{i}^{2}] - 2 \sum_{i=1}^{n} \mathbb{E}[x_{i}\mu] + \sum_{i=1}^{n} \mathbb{E}[\mu^{2}] \right]
				= \frac{1}{n} [n\sigma^{2} + n^{2}\mu^{2} + n^{2}\mu{2} - 2n^{2}\mu^{2}]
				= \frac{1}{n} [n\sigma^{2}] = \sigma^{2}
			\end{align*}
			Hence, $\hat{\sigma}^{2}$ is an unbiased estimator of $\sigma^{2}$.
	\end{itemize}